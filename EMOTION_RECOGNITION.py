# -*- coding: utf-8 -*-
"""EMOTION_RECOGNITION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RPTpSgtwQTjM8bSnQheIvzUq015dUaO7

# IMPORT TH∆Ø VI·ªÜN
"""

!pip install pyvi
!pip install underthesea

from google.colab import drive
drive.mount('/content/drive')

from pandas import read_excel
from underthesea import word_tokenize

my_sheet = 'Sheet1'
file_name_train = '/content/drive/MyDrive/DATAMINING/train_nor_811.xlsx'
file_name_val = '/content/drive/MyDrive/DATAMINING/valid_nor_811.xlsx'

import re
import string
import pandas as pd
from pyvi import ViTokenizer
from underthesea import pos_tag
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from numpy import array
max_fatures = 2000

"""# ƒê·ªåC FILE TRAIN VS VALIDATE"""

df = read_excel(file_name_train, sheet_name = my_sheet)
df = df.drop(['Unnamed: 0'], axis=1)
print(df.head())
X_train = df['Sentence']
y_train = df['Emotion']

df = read_excel(file_name_val, sheet_name = my_sheet)
df =df.drop(['Unnamed: 0'], axis=1)
print(df.head())
X_val = df['Sentence']
y_val = df['Emotion']

"""# PREPROCESSING DATA"""

def normalize_text(text):
  #Remove c√°c k√Ω t·ª± k√©o d√†i: vd: ƒë·∫πppppppp
  text = re.sub(r'([A-Z])\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)
  text = text.replace("\n", " ")
  text = text.lower()
 
  # chuyen punctuation th√†nh space
  translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))
  text = text.translate(translator)

  text = ViTokenizer.tokenize(text)
  texts = text.split()
  texts = [t.replace('_', ' ') for t in texts]
  text = u' '.join(texts)

  #remove n·ªët nh·ªØng k√Ω t·ª± th·ª´a th√£i
  text = text.replace(u'"', u' ')
  text = text.replace(u'Ô∏è', u'')
  text = text.replace('üèª','')

  #segmentation
  text = word_tokenize(text, format="text")
  return text

X_train = X_train.map(lambda x: normalize_text(x))
X_train[:10]

X_val = X_val.map(lambda x: normalize_text(x))
X_val[:10]

"""# L·∫§Y VALIDATE & TRAIN DATASET L√ÄM T·∫¨P TRAIN"""

X = X_train.append(X_val,ignore_index=True)
y = y_train.append(y_val,ignore_index=True)

"""# VECTOR HO√Å FEATURE & LABEL

## feature - X
"""

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
vectorizer = TfidfVectorizer(
    binary=True, ngram_range=(1, 2),
    sublinear_tf=True,
    use_idf=True,
)

vectorizer.fit(X)
X = vectorizer.transform(X)
print(X)

"""## Label - Y"""

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(y.values)
y = le.transform(y.values)

print(y)

"""# MODEL"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

Logistic = LogisticRegression(max_iter=1000)
Logistic.fit(X, y)

"""# TEST DATASET"""

my_sheet = 'Sheet1'
file_name_test = '/content/drive/MyDrive/DATAMINING/test_nor_811.xlsx'

df = read_excel(file_name_test, sheet_name = my_sheet)
df =df.drop(['Unnamed: 0'], axis=1)
print(df.head())
X_test = df['Sentence']
y_test = df['Emotion']

X_test = vectorizer.transform(X_test)
y_test = le.transform(y_test.values)

y_logistic_predict = Logistic.predict(X_test)
print(classification_report(y_test, y_logistic_predict))
print(accuracy_score(y_test, y_logistic_predict))

"""# CRAWL DATASET"""

df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_1.csv', encoding= 'utf-8-sig')
df = df.drop(['Unnamed: 0'], axis=1)
print(df.head())
X_test_crawl_1 = df['comment']
y_test_crawl_1 = df['label']

df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_2.csv', encoding= 'utf-8-sig')
df = df.drop(['Unnamed: 0'], axis=1)
print(df.head())
X_test_crawl_2 = df['comment']
y_test_crawl_2 = df['label']

df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_3.csv', encoding= 'utf-8-sig')
df = df.drop(['Unnamed: 0'], axis=1)
print(df.head())
X_test_crawl_3 = df['comment']
y_test_crawl_3 = df['label']

X_test_crawl_1 = vectorizer.transform(X_test_crawl_1)
y_test_crawl_1 = le.transform(y_test_crawl_1.values)

X_test_crawl_2 = vectorizer.transform(X_test_crawl_2)
y_test_crawl_2 = le.transform(y_test_crawl_2.values)

X_test_crawl_3 = vectorizer.transform(X_test_crawl_3)
y_test_crawl_3 = le.transform(y_test_crawl_3.values)

y_crawl_logistic_predict_1 = Logistic.predict(X_test_crawl_1)
print(classification_report(y_test_crawl_1, y_crawl_logistic_predict_1))
print(accuracy_score(y_test_crawl_1, y_crawl_logistic_predict_1))

y_crawl_logistic_predict_2 = Logistic.predict(X_test_crawl_2)
print(classification_report(y_test_crawl_2, y_crawl_logistic_predict_2))
print(accuracy_score(y_test_crawl_2, y_crawl_logistic_predict_2))

y_crawl_logistic_predict_3 = Logistic.predict(X_test_crawl_3)
print(classification_report(y_test_crawl_3, y_crawl_logistic_predict_3))
print(accuracy_score(y_test_crawl_3, y_crawl_logistic_predict_3))