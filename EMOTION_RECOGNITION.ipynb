{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMOTION_RECOGNITION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYDb98gAyGOR"
      },
      "source": [
        "# IMPORT THƯ VIỆN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hriMAwYfqnS5",
        "outputId": "46713830-63d2-43b1-9829-efa5a221187e"
      },
      "source": [
        "!pip install pyvi\n",
        "!pip install underthesea"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Requirement already satisfied: underthesea in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.13)\n",
            "Requirement already satisfied: transformers<=3.5.1,>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.5.1)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.41.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (0.22.2.post1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from underthesea) (0.9.7)\n",
            "Requirement already satisfied: torch<=1.5.1,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.5.1)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (8.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.9.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.1.91)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (20.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<=1.5.1,>=1.1.0->underthesea) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->underthesea) (56.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<=3.5.1,>=3.5.0->underthesea) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8wXjC37qoG8",
        "outputId": "a754bf50-469a-4a3f-919d-def50985c2a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JXusUwkq3dP"
      },
      "source": [
        "from pandas import read_excel\n",
        "from underthesea import word_tokenize\n",
        "\n",
        "my_sheet = 'Sheet1'\n",
        "file_name_train = '/content/drive/MyDrive/DATAMINING/train_nor_811.xlsx'\n",
        "file_name_val = '/content/drive/MyDrive/DATAMINING/valid_nor_811.xlsx'"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6trMdTCnrR-D"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from pyvi import ViTokenizer\n",
        "from underthesea import pos_tag\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from numpy import array\n",
        "max_fatures = 2000"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-FOiUmXyM2o"
      },
      "source": [
        "# ĐỌC FILE TRAIN VS VALIDATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw2I2XbirVKa",
        "outputId": "745c3f54-7eca-487c-d42d-f1fbb45137a6"
      },
      "source": [
        "df = read_excel(file_name_train, sheet_name = my_sheet)\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_train = df['Sentence']\n",
        "y_train = df['Emotion']"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Emotion                                           Sentence\n",
            "0      Other              cho mình xin bài nhạc tên là gì với ạ\n",
            "1    Disgust  cho đáng đời con quỷ . về nhà lôi con nhà mày ...\n",
            "2    Disgust  lo học đi . yêu đương lol gì hay lại thích học...\n",
            "3  Enjoyment    uớc gì sau này về già vẫn có thể như cụ này :))\n",
            "4  Enjoyment  mỗi lần có video của con là cứ coi đi coi lại ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRVG-QdJrXpa",
        "outputId": "d67435f1-b300-43b0-a5a7-84081f9e76dd"
      },
      "source": [
        "df = read_excel(file_name_val, sheet_name = my_sheet)\n",
        "df =df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_val = df['Sentence']\n",
        "y_val = df['Emotion']"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Emotion                                           Sentence\n",
            "0      Other  tính tao tao biết , chẳng có chuyện gì có thể ...\n",
            "1  Enjoyment           lại là lào cai , tự hào quê mình quá :))\n",
            "2    Sadness                                     bị từ chối rồi\n",
            "3  Enjoyment                         tam đảo trời đẹp các mem à\n",
            "4      Other  đọc bình luận của thằng đó không thiếu chữ nào 😂😂\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS5Ko0q-yTs_"
      },
      "source": [
        "# PREPROCESSING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRcr0qG5raBq"
      },
      "source": [
        "def normalize_text(text):\n",
        "  #Remove các ký tự kéo dài: vd: đẹppppppp\n",
        "  text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
        "  text = text.replace(\"\\n\", \" \")\n",
        "  text = text.lower()\n",
        " \n",
        "  # chuyen punctuation thành space\n",
        "  translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "  text = text.translate(translator)\n",
        "\n",
        "  text = ViTokenizer.tokenize(text)\n",
        "  texts = text.split()\n",
        "  texts = [t.replace('_', ' ') for t in texts]\n",
        "  text = u' '.join(texts)\n",
        "\n",
        "  #remove nốt những ký tự thừa thãi\n",
        "  text = text.replace(u'\"', u' ')\n",
        "  text = text.replace(u'️', u'')\n",
        "  text = text.replace('🏻','')\n",
        "\n",
        "  #segmentation\n",
        "  text = word_tokenize(text, format=\"text\")\n",
        "  return text"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz4llOEZryoZ",
        "outputId": "d18fe34c-e337-4952-8894-6502ddbf56a2"
      },
      "source": [
        "X_train = X_train.map(lambda x: normalize_text(x))\n",
        "X_train[:10]"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                cho mình xin bài nhạc tên là gì với ạ\n",
              "1    cho đáng đời con quỷ về nhà lôi con nhà mày ra...\n",
              "2    lo học đi yêu_đương lol gì hay lại thích học_s...\n",
              "3          uớc gì sau_này về già vẫn có_thể như cụ này\n",
              "4    mỗi lần có video của con là cứ coi đi coi lại ...\n",
              "5    thằng kia sao mày bắt vợ với bồ tao dọn thế ki...\n",
              "6                        một lí_do trog muôn_vàn lí_do\n",
              "7               thật hay đùa ác vậy không_thể tin được\n",
              "8    ko phải con mình mà xem còn thấy đau như vậy h...\n",
              "9    per nghe đi rồi khóc 1 trận cho thoải_mái đừng...\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adELJdOor01Z",
        "outputId": "a0f4d457-1358-4556-fdb7-97649a2b02ce"
      },
      "source": [
        "X_val = X_val.map(lambda x: normalize_text(x))\n",
        "X_val[:10]"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    tính tao tao biết chẳng có chuyện gì có_thể là...\n",
              "1                   lại là lào cai tự_hào quê mình quá\n",
              "2                                       bị từ_chối rồi\n",
              "3                           tam_đảo trời đẹp các mem à\n",
              "4    đọc bình_luận của thằng đó không thiếu chữ nào...\n",
              "5                        crush tao vẫn còn trinh nhé 😘\n",
              "6    nó nói không đúg ư đg của nhà bà ư nó đóg phí ...\n",
              "7                    gap kiểu này chắc đái ra quần quá\n",
              "8                                   yêu em mọa mọa 😘 😘\n",
              "9    có ai như tao không đọc đề thì quen nhưng lại ...\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRyQQqCvycwZ"
      },
      "source": [
        "# LẤY VALIDATE & TRAIN DATASET LÀM TẬP TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR6Sx3V5uyUs"
      },
      "source": [
        "X = X_train.append(X_val,ignore_index=True)\n",
        "y = y_train.append(y_val,ignore_index=True)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2OLot35ymfq"
      },
      "source": [
        "# VECTOR HOÁ FEATURE & LABEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFjhch8rKmDG"
      },
      "source": [
        "## feature - X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsOFFR-TuBfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53c95cb-6376-4d15-992b-06b29ff83fe1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        "    binary=True, ngram_range=(1, 2),\n",
        "    sublinear_tf=True,\n",
        "    use_idf=True,\n",
        ")\n",
        "\n",
        "vectorizer.fit(X)\n",
        "X = vectorizer.transform(X)\n",
        "print(X)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 42026)\t0.3194230222694976\n",
            "  (0, 42025)\t0.22273969491569742\n",
            "  (0, 41375)\t0.155019455465049\n",
            "  (0, 38054)\t0.30878650685603176\n",
            "  (0, 38046)\t0.23684005876057176\n",
            "  (0, 25821)\t0.3344143487545289\n",
            "  (0, 25803)\t0.2425394965740062\n",
            "  (0, 21388)\t0.2937951803710005\n",
            "  (0, 21209)\t0.14012453884016166\n",
            "  (0, 17504)\t0.2492805007405798\n",
            "  (0, 17349)\t0.1047146669770741\n",
            "  (0, 12588)\t0.3194230222694976\n",
            "  (0, 12425)\t0.12917560617270482\n",
            "  (0, 3833)\t0.2492805007405798\n",
            "  (0, 3707)\t0.1258152135705541\n",
            "  (0, 1383)\t0.2937951803710005\n",
            "  (0, 1365)\t0.20041101003859368\n",
            "  (1, 47293)\t0.24631804353097653\n",
            "  (1, 47282)\t0.1519997076196926\n",
            "  (1, 44528)\t0.16726801349233955\n",
            "  (1, 44525)\t0.25787836934434744\n",
            "  (1, 44497)\t0.13842598516918578\n",
            "  (1, 41244)\t0.20239799661490518\n",
            "  (1, 41178)\t0.12834325794033932\n",
            "  (1, 30644)\t0.21835335432502892\n",
            "  :\t:\n",
            "  (6233, 20984)\t0.17325919566905473\n",
            "  (6233, 20829)\t0.07696035242838022\n",
            "  (6233, 18731)\t0.17325919566905473\n",
            "  (6233, 18702)\t0.10747877627415438\n",
            "  (6233, 18025)\t0.14444754435215154\n",
            "  (6233, 17868)\t0.0724983860196208\n",
            "  (6233, 16882)\t0.17325919566905473\n",
            "  (6233, 16880)\t0.15570700777749302\n",
            "  (6233, 14343)\t0.17325919566905473\n",
            "  (6233, 14331)\t0.11493924545227534\n",
            "  (6233, 10736)\t0.17325919566905473\n",
            "  (6233, 10735)\t0.14444754435215154\n",
            "  (6233, 10358)\t0.1654922287955272\n",
            "  (6233, 10330)\t0.09684742476907969\n",
            "  (6233, 9373)\t0.14242929020764492\n",
            "  (6233, 9336)\t0.09950693367985228\n",
            "  (6233, 8658)\t0.1654922287955272\n",
            "  (6233, 8459)\t0.06700007812808488\n",
            "  (6233, 3855)\t0.13466232333411735\n",
            "  (6233, 3831)\t0.14242929020764492\n",
            "  (6233, 3707)\t0.06518453166662853\n",
            "  (6233, 3112)\t0.1654922287955272\n",
            "  (6233, 3110)\t0.12487710231608319\n",
            "  (6233, 635)\t0.17325919566905473\n",
            "  (6233, 624)\t0.13013413145821184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0BnADoTKo_f"
      },
      "source": [
        "## Label - Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ3IeOPCvEYI"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y.values)\n",
        "y = le.transform(y.values)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29GfBOE4vL44",
        "outputId": "733fb7d6-6f5a-4321-92cb-5c11413eb26d"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 1 1 ... 1 6 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oji1zf74yxws"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjLvgk7AvOWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdad3147-0882-4e84-9b31-63ddc2b259e2"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "Logistic = LogisticRegression(max_iter=1000)\n",
        "Logistic.fit(X, y)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3kir3eszDhm"
      },
      "source": [
        "# TEST DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD62aJeKwaiA"
      },
      "source": [
        "my_sheet = 'Sheet1'\n",
        "file_name_test = '/content/drive/MyDrive/DATAMINING/test_nor_811.xlsx'"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp3HHZcJwkII",
        "outputId": "06c246c8-7099-41d3-86a3-a05ea0565267"
      },
      "source": [
        "df = read_excel(file_name_test, sheet_name = my_sheet)\n",
        "df =df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test = df['Sentence']\n",
        "y_test = df['Emotion']"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Emotion                                           Sentence\n",
            "0   Sadness                   người ta có bạn bè nhìn vui thật\n",
            "1  Surprise          cho nghỉ viêc mói đúng sao goi là kỷ luật\n",
            "2   Disgust                                         kinh vãi 😡\n",
            "3      Fear  nhà thì không xa lắm nhưng chưa bao giờ đi vì ...\n",
            "4     Anger      bố không thích nộp đấy mày thích ý kiến không\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDkwMzSsxo6j"
      },
      "source": [
        "X_test = vectorizer.transform(X_test)\n",
        "y_test = le.transform(y_test.values)"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5N8Zt4bxeeK",
        "outputId": "1cf60052-a106-40fb-90d7-d15a5c56ecc0"
      },
      "source": [
        "y_logistic_predict = Logistic.predict(X_test)\n",
        "print(classification_report(y_test, y_logistic_predict))\n",
        "print(accuracy_score(y_test, y_logistic_predict))"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.10      0.17        40\n",
            "           1       0.43      0.54      0.48       132\n",
            "           2       0.48      0.71      0.57       193\n",
            "           3       0.90      0.39      0.55        46\n",
            "           4       0.42      0.37      0.40       129\n",
            "           5       0.60      0.50      0.55       116\n",
            "           6       0.67      0.11      0.19        37\n",
            "\n",
            "    accuracy                           0.49       693\n",
            "   macro avg       0.57      0.39      0.41       693\n",
            "weighted avg       0.52      0.49      0.47       693\n",
            "\n",
            "0.4906204906204906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzwX_-bbz1j7"
      },
      "source": [
        "# CRAWL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmLn5chZzzrA",
        "outputId": "f5e6bc52-b548-45c1-cfab-4191135de0de"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_1.csv', encoding= 'utf-8-sig')\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test_crawl_1 = df['comment']\n",
        "y_test_crawl_1 = df['label']\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_2.csv', encoding= 'utf-8-sig')\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test_crawl_2 = df['comment']\n",
        "y_test_crawl_2 = df['label']\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_3.csv', encoding= 'utf-8-sig')\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test_crawl_3 = df['comment']\n",
        "y_test_crawl_3 = df['label']"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             comment      label\n",
            "0  Dù cho tất cả thế giới có quay lưng với em anh...  Enjoyment\n",
            "1  thằng bạn t bị câm từ nhỏ nghe xong bài này nó...    Disgust\n",
            "2                   Có ai từ Mv Răng khôn qua đây ko  Enjoyment\n",
            "3  Cơm sườn hay bún mắm\\nAnh mún ăn cơm sườn hay ...  Enjoyment\n",
            "4              Tự nhiên t thấy yêu Chi Pu ghê =)))))  Enjoyment\n",
            "                                             comment      label\n",
            "0  05:45  Có những cuộc gặp gỡ chớp nhoáng...      Other\n",
            "1  Từ đoạn Hiền Hồ cao trào và luôn cả đoạn cuối ...  Enjoyment\n",
            "2  Một sự kết hợp quá tuyệt vờiiiiiiii.. Hy vọng ...  Enjoyment\n",
            "3  Hai ông bà này có điểm chung là\\n- Hát hay\\n- ...  Enjoyment\n",
            "4  03:41  Anh ghét em lắm em biết không? Vì suốt ...    Sadness\n",
            "                                             comment    label\n",
            "0        Ngồi sau xe bạn hiền cảm giác ấm áp lạ kỳ..    Other\n",
            "1  Mỗi lần mệt mỏi nghe nhạc cảm thấy bình yên đế...    Other\n",
            "2  Mỗi lần nghe bài này đều khóc, khóc là vì khôn...  Sadness\n",
            "3  Gần Tết  mà nghe bài này nữa thì chỉ muốn về n...  Sadness\n",
            "4                  Có ai từ Trốn Tìm qua đây khônggg    Other\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGiZOrRH0BOh"
      },
      "source": [
        "X_test_crawl_1 = vectorizer.transform(X_test_crawl_1)\n",
        "y_test_crawl_1 = le.transform(y_test_crawl_1.values)\n",
        "\n",
        "X_test_crawl_2 = vectorizer.transform(X_test_crawl_2)\n",
        "y_test_crawl_2 = le.transform(y_test_crawl_2.values)\n",
        "\n",
        "X_test_crawl_3 = vectorizer.transform(X_test_crawl_3)\n",
        "y_test_crawl_3 = le.transform(y_test_crawl_3.values)"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jVsYfUA0TGy",
        "outputId": "b829ce9b-6c39-4eea-8489-75c93d52ad7a"
      },
      "source": [
        "y_crawl_logistic_predict_1 = Logistic.predict(X_test_crawl_1)\n",
        "print(classification_report(y_test_crawl_1, y_crawl_logistic_predict_1))\n",
        "print(accuracy_score(y_test_crawl_1, y_crawl_logistic_predict_1))\n",
        "\n",
        "y_crawl_logistic_predict_2 = Logistic.predict(X_test_crawl_2)\n",
        "print(classification_report(y_test_crawl_2, y_crawl_logistic_predict_2))\n",
        "print(accuracy_score(y_test_crawl_2, y_crawl_logistic_predict_2))\n",
        "\n",
        "y_crawl_logistic_predict_3 = Logistic.predict(X_test_crawl_3)\n",
        "print(classification_report(y_test_crawl_3, y_crawl_logistic_predict_3))\n",
        "print(accuracy_score(y_test_crawl_3, y_crawl_logistic_predict_3))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         8\n",
            "           1       0.29      0.80      0.42         5\n",
            "           2       0.49      0.88      0.63        41\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.41      0.37      0.39        30\n",
            "           5       0.83      0.42      0.56        12\n",
            "           6       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.47       120\n",
            "   macro avg       0.29      0.35      0.28       120\n",
            "weighted avg       0.37      0.47      0.39       120\n",
            "\n",
            "0.4666666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.47      0.96      0.63        45\n",
            "           4       0.33      0.10      0.15        21\n",
            "           5       0.33      0.60      0.43         5\n",
            "           6       0.00      0.00      0.00        38\n",
            "\n",
            "    accuracy                           0.44       109\n",
            "   macro avg       0.23      0.33      0.24       109\n",
            "weighted avg       0.27      0.44      0.31       109\n",
            "\n",
            "0.44036697247706424\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.43      0.72      0.54        39\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.50      0.25      0.33        40\n",
            "           5       0.50      0.57      0.53        21\n",
            "           6       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.45       111\n",
            "   macro avg       0.24      0.26      0.23       111\n",
            "weighted avg       0.43      0.45      0.41       111\n",
            "\n",
            "0.45045045045045046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}