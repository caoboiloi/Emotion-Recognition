{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMOTION_RECOGNITION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYDb98gAyGOR"
      },
      "source": [
        "# IMPORT TH∆Ø VI·ªÜN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hriMAwYfqnS5",
        "outputId": "46713830-63d2-43b1-9829-efa5a221187e"
      },
      "source": [
        "!pip install pyvi\n",
        "!pip install underthesea"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Requirement already satisfied: underthesea in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.13)\n",
            "Requirement already satisfied: transformers<=3.5.1,>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.5.1)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.41.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (0.22.2.post1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from underthesea) (0.9.7)\n",
            "Requirement already satisfied: torch<=1.5.1,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.5.1)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (8.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.9.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.1.91)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (20.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<=1.5.1,>=1.1.0->underthesea) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->underthesea) (56.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<=3.5.1,>=3.5.0->underthesea) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8wXjC37qoG8",
        "outputId": "a754bf50-469a-4a3f-919d-def50985c2a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JXusUwkq3dP"
      },
      "source": [
        "from pandas import read_excel\n",
        "from underthesea import word_tokenize\n",
        "\n",
        "my_sheet = 'Sheet1'\n",
        "file_name_train = '/content/drive/MyDrive/DATAMINING/train_nor_811.xlsx'\n",
        "file_name_val = '/content/drive/MyDrive/DATAMINING/valid_nor_811.xlsx'"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6trMdTCnrR-D"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from pyvi import ViTokenizer\n",
        "from underthesea import pos_tag\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from numpy import array\n",
        "max_fatures = 2000"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-FOiUmXyM2o"
      },
      "source": [
        "# ƒê·ªåC FILE TRAIN VS VALIDATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw2I2XbirVKa",
        "outputId": "745c3f54-7eca-487c-d42d-f1fbb45137a6"
      },
      "source": [
        "df = read_excel(file_name_train, sheet_name = my_sheet)\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_train = df['Sentence']\n",
        "y_train = df['Emotion']"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Emotion                                           Sentence\n",
            "0      Other              cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°\n",
            "1    Disgust  cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ...\n",
            "2    Disgust  lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc...\n",
            "3  Enjoyment    u·ªõc g√¨ sau n√†y v·ªÅ gi√† v·∫´n c√≥ th·ªÉ nh∆∞ c·ª• n√†y :))\n",
            "4  Enjoyment  m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRVG-QdJrXpa",
        "outputId": "d67435f1-b300-43b0-a5a7-84081f9e76dd"
      },
      "source": [
        "df = read_excel(file_name_val, sheet_name = my_sheet)\n",
        "df =df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_val = df['Sentence']\n",
        "y_val = df['Emotion']"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Emotion                                           Sentence\n",
            "0      Other  t√≠nh tao tao bi·∫øt , ch·∫≥ng c√≥ chuy·ªán g√¨ c√≥ th·ªÉ ...\n",
            "1  Enjoyment           l·∫°i l√† l√†o cai , t·ª± h√†o qu√™ m√¨nh qu√° :))\n",
            "2    Sadness                                     b·ªã t·ª´ ch·ªëi r·ªìi\n",
            "3  Enjoyment                         tam ƒë·∫£o tr·ªùi ƒë·∫πp c√°c mem √†\n",
            "4      Other  ƒë·ªçc b√¨nh lu·∫≠n c·ªßa th·∫±ng ƒë√≥ kh√¥ng thi·∫øu ch·ªØ n√†o üòÇüòÇ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS5Ko0q-yTs_"
      },
      "source": [
        "# PREPROCESSING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRcr0qG5raBq"
      },
      "source": [
        "def normalize_text(text):\n",
        "  #Remove c√°c k√Ω t·ª± k√©o d√†i: vd: ƒë·∫πppppppp\n",
        "  text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
        "  text = text.replace(\"\\n\", \" \")\n",
        "  text = text.lower()\n",
        " \n",
        "  # chuyen punctuation th√†nh space\n",
        "  translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "  text = text.translate(translator)\n",
        "\n",
        "  text = ViTokenizer.tokenize(text)\n",
        "  texts = text.split()\n",
        "  texts = [t.replace('_', ' ') for t in texts]\n",
        "  text = u' '.join(texts)\n",
        "\n",
        "  #remove n·ªët nh·ªØng k√Ω t·ª± th·ª´a th√£i\n",
        "  text = text.replace(u'\"', u' ')\n",
        "  text = text.replace(u'Ô∏è', u'')\n",
        "  text = text.replace('üèª','')\n",
        "\n",
        "  #segmentation\n",
        "  text = word_tokenize(text, format=\"text\")\n",
        "  return text"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz4llOEZryoZ",
        "outputId": "d18fe34c-e337-4952-8894-6502ddbf56a2"
      },
      "source": [
        "X_train = X_train.map(lambda x: normalize_text(x))\n",
        "X_train[:10]"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°\n",
              "1    cho ƒë√°ng ƒë·ªùi con qu·ª∑ v·ªÅ nh√† l√¥i con nh√† m√†y ra...\n",
              "2    lo h·ªçc ƒëi y√™u_ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc_s...\n",
              "3          u·ªõc g√¨ sau_n√†y v·ªÅ gi√† v·∫´n c√≥_th·ªÉ nh∆∞ c·ª• n√†y\n",
              "4    m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ...\n",
              "5    th·∫±ng kia sao m√†y b·∫Øt v·ª£ v·ªõi b·ªì tao d·ªçn th·∫ø ki...\n",
              "6                        m·ªôt l√≠_do trog mu√¥n_v√†n l√≠_do\n",
              "7               th·∫≠t hay ƒë√πa √°c v·∫≠y kh√¥ng_th·ªÉ tin ƒë∆∞·ª£c\n",
              "8    ko ph·∫£i con m√¨nh m√† xem c√≤n th·∫•y ƒëau nh∆∞ v·∫≠y h...\n",
              "9    per nghe ƒëi r·ªìi kh√≥c 1 tr·∫≠n cho tho·∫£i_m√°i ƒë·ª´ng...\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adELJdOor01Z",
        "outputId": "a0f4d457-1358-4556-fdb7-97649a2b02ce"
      },
      "source": [
        "X_val = X_val.map(lambda x: normalize_text(x))\n",
        "X_val[:10]"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    t√≠nh tao tao bi·∫øt ch·∫≥ng c√≥ chuy·ªán g√¨ c√≥_th·ªÉ l√†...\n",
              "1                   l·∫°i l√† l√†o cai t·ª±_h√†o qu√™ m√¨nh qu√°\n",
              "2                                       b·ªã t·ª´_ch·ªëi r·ªìi\n",
              "3                           tam_ƒë·∫£o tr·ªùi ƒë·∫πp c√°c mem √†\n",
              "4    ƒë·ªçc b√¨nh_lu·∫≠n c·ªßa th·∫±ng ƒë√≥ kh√¥ng thi·∫øu ch·ªØ n√†o...\n",
              "5                        crush tao v·∫´n c√≤n trinh nh√© üòò\n",
              "6    n√≥ n√≥i kh√¥ng ƒë√∫g ∆∞ ƒëg c·ªßa nh√† b√† ∆∞ n√≥ ƒë√≥g ph√≠ ...\n",
              "7                    gap ki·ªÉu n√†y ch·∫Øc ƒë√°i ra qu·∫ßn qu√°\n",
              "8                                   y√™u em m·ªça m·ªça üòò üòò\n",
              "9    c√≥ ai nh∆∞ tao kh√¥ng ƒë·ªçc ƒë·ªÅ th√¨ quen nh∆∞ng l·∫°i ...\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRyQQqCvycwZ"
      },
      "source": [
        "# L·∫§Y VALIDATE & TRAIN DATASET L√ÄM T·∫¨P TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR6Sx3V5uyUs"
      },
      "source": [
        "X = X_train.append(X_val,ignore_index=True)\n",
        "y = y_train.append(y_val,ignore_index=True)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2OLot35ymfq"
      },
      "source": [
        "# VECTOR HO√Å FEATURE & LABEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFjhch8rKmDG"
      },
      "source": [
        "## feature - X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsOFFR-TuBfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53c95cb-6376-4d15-992b-06b29ff83fe1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        "    binary=True, ngram_range=(1, 2),\n",
        "    sublinear_tf=True,\n",
        "    use_idf=True,\n",
        ")\n",
        "\n",
        "vectorizer.fit(X)\n",
        "X = vectorizer.transform(X)\n",
        "print(X)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 42026)\t0.3194230222694976\n",
            "  (0, 42025)\t0.22273969491569742\n",
            "  (0, 41375)\t0.155019455465049\n",
            "  (0, 38054)\t0.30878650685603176\n",
            "  (0, 38046)\t0.23684005876057176\n",
            "  (0, 25821)\t0.3344143487545289\n",
            "  (0, 25803)\t0.2425394965740062\n",
            "  (0, 21388)\t0.2937951803710005\n",
            "  (0, 21209)\t0.14012453884016166\n",
            "  (0, 17504)\t0.2492805007405798\n",
            "  (0, 17349)\t0.1047146669770741\n",
            "  (0, 12588)\t0.3194230222694976\n",
            "  (0, 12425)\t0.12917560617270482\n",
            "  (0, 3833)\t0.2492805007405798\n",
            "  (0, 3707)\t0.1258152135705541\n",
            "  (0, 1383)\t0.2937951803710005\n",
            "  (0, 1365)\t0.20041101003859368\n",
            "  (1, 47293)\t0.24631804353097653\n",
            "  (1, 47282)\t0.1519997076196926\n",
            "  (1, 44528)\t0.16726801349233955\n",
            "  (1, 44525)\t0.25787836934434744\n",
            "  (1, 44497)\t0.13842598516918578\n",
            "  (1, 41244)\t0.20239799661490518\n",
            "  (1, 41178)\t0.12834325794033932\n",
            "  (1, 30644)\t0.21835335432502892\n",
            "  :\t:\n",
            "  (6233, 20984)\t0.17325919566905473\n",
            "  (6233, 20829)\t0.07696035242838022\n",
            "  (6233, 18731)\t0.17325919566905473\n",
            "  (6233, 18702)\t0.10747877627415438\n",
            "  (6233, 18025)\t0.14444754435215154\n",
            "  (6233, 17868)\t0.0724983860196208\n",
            "  (6233, 16882)\t0.17325919566905473\n",
            "  (6233, 16880)\t0.15570700777749302\n",
            "  (6233, 14343)\t0.17325919566905473\n",
            "  (6233, 14331)\t0.11493924545227534\n",
            "  (6233, 10736)\t0.17325919566905473\n",
            "  (6233, 10735)\t0.14444754435215154\n",
            "  (6233, 10358)\t0.1654922287955272\n",
            "  (6233, 10330)\t0.09684742476907969\n",
            "  (6233, 9373)\t0.14242929020764492\n",
            "  (6233, 9336)\t0.09950693367985228\n",
            "  (6233, 8658)\t0.1654922287955272\n",
            "  (6233, 8459)\t0.06700007812808488\n",
            "  (6233, 3855)\t0.13466232333411735\n",
            "  (6233, 3831)\t0.14242929020764492\n",
            "  (6233, 3707)\t0.06518453166662853\n",
            "  (6233, 3112)\t0.1654922287955272\n",
            "  (6233, 3110)\t0.12487710231608319\n",
            "  (6233, 635)\t0.17325919566905473\n",
            "  (6233, 624)\t0.13013413145821184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0BnADoTKo_f"
      },
      "source": [
        "## Label - Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ3IeOPCvEYI"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y.values)\n",
        "y = le.transform(y.values)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29GfBOE4vL44",
        "outputId": "733fb7d6-6f5a-4321-92cb-5c11413eb26d"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 1 1 ... 1 6 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oji1zf74yxws"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjLvgk7AvOWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdad3147-0882-4e84-9b31-63ddc2b259e2"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "Logistic = LogisticRegression(max_iter=1000)\n",
        "Logistic.fit(X, y)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3kir3eszDhm"
      },
      "source": [
        "# TEST DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD62aJeKwaiA"
      },
      "source": [
        "my_sheet = 'Sheet1'\n",
        "file_name_test = '/content/drive/MyDrive/DATAMINING/test_nor_811.xlsx'"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp3HHZcJwkII",
        "outputId": "06c246c8-7099-41d3-86a3-a05ea0565267"
      },
      "source": [
        "df = read_excel(file_name_test, sheet_name = my_sheet)\n",
        "df =df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test = df['Sentence']\n",
        "y_test = df['Emotion']"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Emotion                                           Sentence\n",
            "0   Sadness                   ng∆∞·ªùi ta c√≥ b·∫°n b√® nh√¨n vui th·∫≠t\n",
            "1  Surprise          cho ngh·ªâ vi√™c m√≥i ƒë√∫ng sao goi l√† k·ª∑ lu·∫≠t\n",
            "2   Disgust                                         kinh v√£i üò°\n",
            "3      Fear  nh√† th√¨ kh√¥ng xa l·∫Øm nh∆∞ng ch∆∞a bao gi·ªù ƒëi v√¨ ...\n",
            "4     Anger      b·ªë kh√¥ng th√≠ch n·ªôp ƒë·∫•y m√†y th√≠ch √Ω ki·∫øn kh√¥ng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDkwMzSsxo6j"
      },
      "source": [
        "X_test = vectorizer.transform(X_test)\n",
        "y_test = le.transform(y_test.values)"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5N8Zt4bxeeK",
        "outputId": "1cf60052-a106-40fb-90d7-d15a5c56ecc0"
      },
      "source": [
        "y_logistic_predict = Logistic.predict(X_test)\n",
        "print(classification_report(y_test, y_logistic_predict))\n",
        "print(accuracy_score(y_test, y_logistic_predict))"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.10      0.17        40\n",
            "           1       0.43      0.54      0.48       132\n",
            "           2       0.48      0.71      0.57       193\n",
            "           3       0.90      0.39      0.55        46\n",
            "           4       0.42      0.37      0.40       129\n",
            "           5       0.60      0.50      0.55       116\n",
            "           6       0.67      0.11      0.19        37\n",
            "\n",
            "    accuracy                           0.49       693\n",
            "   macro avg       0.57      0.39      0.41       693\n",
            "weighted avg       0.52      0.49      0.47       693\n",
            "\n",
            "0.4906204906204906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzwX_-bbz1j7"
      },
      "source": [
        "# CRAWL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmLn5chZzzrA",
        "outputId": "f5e6bc52-b548-45c1-cfab-4191135de0de"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_1.csv', encoding= 'utf-8-sig')\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test_crawl_1 = df['comment']\n",
        "y_test_crawl_1 = df['label']\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_2.csv', encoding= 'utf-8-sig')\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test_crawl_2 = df['comment']\n",
        "y_test_crawl_2 = df['label']\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/DATAMINING/GFG_3.csv', encoding= 'utf-8-sig')\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head())\n",
        "X_test_crawl_3 = df['comment']\n",
        "y_test_crawl_3 = df['label']"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             comment      label\n",
            "0  D√π cho t·∫•t c·∫£ th·∫ø gi·ªõi c√≥ quay l∆∞ng v·ªõi em anh...  Enjoyment\n",
            "1  th·∫±ng b·∫°n t b·ªã c√¢m t·ª´ nh·ªè nghe xong b√†i n√†y n√≥...    Disgust\n",
            "2                   C√≥ ai t·ª´ Mv RƒÉng kh√¥n qua ƒë√¢y ko  Enjoyment\n",
            "3  C∆°m s∆∞·ªùn hay b√∫n m·∫Øm\\nAnh m√∫n ƒÉn c∆°m s∆∞·ªùn hay ...  Enjoyment\n",
            "4              T·ª± nhi√™n t th·∫•y y√™u Chi Pu gh√™ =)))))  Enjoyment\n",
            "                                             comment      label\n",
            "0  05:45  CoÃÅ nh∆∞ÃÉng cu√¥Ã£c gƒÉÃ£p g∆°ÃÉ ch∆°ÃÅp nhoaÃÅng...      Other\n",
            "1  T·ª´ ƒëo·∫°n Hi·ªÅn H·ªì cao tr√†o v√† lu√¥n c·∫£ ƒëo·∫°n cu·ªëi ...  Enjoyment\n",
            "2  M·ªôt s·ª± k·∫øt h·ª£p qu√° tuy·ªát v·ªùiiiiiiii.. Hy v·ªçng ...  Enjoyment\n",
            "3  Hai √¥ng b√† n√†y c√≥ ƒëi·ªÉm chung l√†\\n- H√°t hay\\n- ...  Enjoyment\n",
            "4  03:41  Anh gh√©t em l·∫Øm em bi·∫øt kh√¥ng? V√¨ su·ªët ...    Sadness\n",
            "                                             comment    label\n",
            "0        Ng·ªìi sau xe b·∫°n hi·ªÅn c·∫£m gi√°c ·∫•m √°p l·∫° k·ª≥..    Other\n",
            "1  M·ªói l·∫ßn m·ªát m·ªèi nghe nh·∫°c c·∫£m th·∫•y b√¨nh y√™n ƒë·∫ø...    Other\n",
            "2  M·ªói l·∫ßn nghe b√†i n√†y ƒë·ªÅu kh√≥c, kh√≥c l√† v√¨ kh√¥n...  Sadness\n",
            "3  G·∫ßn T·∫øt  m√† nghe b√†i n√†y n·ªØa th√¨ ch·ªâ mu·ªën v·ªÅ n...  Sadness\n",
            "4                  C√≥ ai t·ª´ Tr·ªën T√¨m qua ƒë√¢y kh√¥nggg    Other\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGiZOrRH0BOh"
      },
      "source": [
        "X_test_crawl_1 = vectorizer.transform(X_test_crawl_1)\n",
        "y_test_crawl_1 = le.transform(y_test_crawl_1.values)\n",
        "\n",
        "X_test_crawl_2 = vectorizer.transform(X_test_crawl_2)\n",
        "y_test_crawl_2 = le.transform(y_test_crawl_2.values)\n",
        "\n",
        "X_test_crawl_3 = vectorizer.transform(X_test_crawl_3)\n",
        "y_test_crawl_3 = le.transform(y_test_crawl_3.values)"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jVsYfUA0TGy",
        "outputId": "b829ce9b-6c39-4eea-8489-75c93d52ad7a"
      },
      "source": [
        "y_crawl_logistic_predict_1 = Logistic.predict(X_test_crawl_1)\n",
        "print(classification_report(y_test_crawl_1, y_crawl_logistic_predict_1))\n",
        "print(accuracy_score(y_test_crawl_1, y_crawl_logistic_predict_1))\n",
        "\n",
        "y_crawl_logistic_predict_2 = Logistic.predict(X_test_crawl_2)\n",
        "print(classification_report(y_test_crawl_2, y_crawl_logistic_predict_2))\n",
        "print(accuracy_score(y_test_crawl_2, y_crawl_logistic_predict_2))\n",
        "\n",
        "y_crawl_logistic_predict_3 = Logistic.predict(X_test_crawl_3)\n",
        "print(classification_report(y_test_crawl_3, y_crawl_logistic_predict_3))\n",
        "print(accuracy_score(y_test_crawl_3, y_crawl_logistic_predict_3))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         8\n",
            "           1       0.29      0.80      0.42         5\n",
            "           2       0.49      0.88      0.63        41\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.41      0.37      0.39        30\n",
            "           5       0.83      0.42      0.56        12\n",
            "           6       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.47       120\n",
            "   macro avg       0.29      0.35      0.28       120\n",
            "weighted avg       0.37      0.47      0.39       120\n",
            "\n",
            "0.4666666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.47      0.96      0.63        45\n",
            "           4       0.33      0.10      0.15        21\n",
            "           5       0.33      0.60      0.43         5\n",
            "           6       0.00      0.00      0.00        38\n",
            "\n",
            "    accuracy                           0.44       109\n",
            "   macro avg       0.23      0.33      0.24       109\n",
            "weighted avg       0.27      0.44      0.31       109\n",
            "\n",
            "0.44036697247706424\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.43      0.72      0.54        39\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.50      0.25      0.33        40\n",
            "           5       0.50      0.57      0.53        21\n",
            "           6       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.45       111\n",
            "   macro avg       0.24      0.26      0.23       111\n",
            "weighted avg       0.43      0.45      0.41       111\n",
            "\n",
            "0.45045045045045046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}